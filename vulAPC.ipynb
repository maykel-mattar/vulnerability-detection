{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vulnerability Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the required databases in neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class DBManager:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.driver = GraphDatabase.driver(\"bolt://neo4j:7687\")\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def addDB(self, modes):\n",
    "        for modeitem in modes:\n",
    "            with self.driver.session() as session:\n",
    "                greeting = session.execute_write(self._addDBitem, modeitem)\n",
    "\n",
    "    @staticmethod\n",
    "    def _addDBitem(tx, modeitem):\n",
    "        result = tx.run(\"CREATE database \"\n",
    "                        \"$modeitem \", modeitem=modeitem)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    greeter = DBManager()\n",
    "    modes = ['ast','cfg','pdg','mixte','astcfg','astpdg','cfgpdg']\n",
    "    greeter.addDB(modes)\n",
    "    greeter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import stellargraph as sg\n",
    "import numpy as np\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph import datasets\n",
    "import py2neo\n",
    "from stellargraph import StellarDiGraph\n",
    "from sklearn import model_selection\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the datasets in neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',max_categories=10)\n",
    "def getDataSet(db):\n",
    "    default_host = os.environ.get(\"STELLARGRAPH_NEO4J_HOST\")\n",
    "    neo4j_graph = py2neo.Graph(host='neo4j', port=7687,name=db)\n",
    "    num_nodes = len(neo4j_graph.nodes)\n",
    "    num_relationships = len(neo4j_graph.relationships)\n",
    "    nodesLabelList = neo4j_graph\n",
    "    nodesLabelsraw =neo4j_graph.run(\"MATCH (n) RETURN distinct labels(n)[0] \")\n",
    "    raw_homogeneous_nodes = neo4j_graph.run(\n",
    "        ' MATCH (n) RETURN n.id AS id, n.line as line , toFloat(n.typeInt) as type, labels(n)[0] as nodeTypeLabel'\n",
    "    )\n",
    "    raw_homogeneous_nodesUpdated=[]\n",
    "    for item in raw_homogeneous_nodes:\n",
    "        raw_homogeneous_nodesUpdated.append({ \"id\":item['id'],\n",
    "                                              'line':item['line'],\n",
    "                                               'nodeTypeLabel':item['nodeTypeLabel'] if item['nodeTypeLabel']  else 'default'\n",
    "                                             })\n",
    "    raw_homogeneous_nodesUpdated = pd.DataFrame(raw_homogeneous_nodesUpdated)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(raw_homogeneous_nodesUpdated[['nodeTypeLabel']]).toarray())\n",
    "    final_df = raw_homogeneous_nodesUpdated.join(encoder_df)\n",
    "    final_df.drop('nodeTypeLabel', axis=1, inplace=True)\n",
    "    homogeneous_nodes = final_df.set_index(\"id\")\n",
    "    edges = neo4j_graph.run(\n",
    "        \"\"\"\n",
    "        MATCH (s) -[r]-> (t)\n",
    "        RETURN s.id AS source, t.id AS target, type(r) as type\n",
    "        \"\"\"\n",
    "    ).to_data_frame()\n",
    "    edges.head()\n",
    "    homogeneous = StellarDiGraph(homogeneous_nodes, edges,edge_type_column=\"type\")\n",
    "    return homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllLabels(filePath):\n",
    "    files = os.listdir(filePath)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "DataLoading"
    ]
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "datasetArray = []\n",
    "labelsArray = []\n",
    "dirPath = \"./juliet2\"\n",
    "files = os.listdir(dirPath)\n",
    "labelsArr = (getAllLabels(dirPath))\n",
    "\n",
    "mode = 'mixte'\n",
    "for file in files:\n",
    "    subFile = os.listdir(dirPath+\"/\"+file)\n",
    "    vulName =file[:file.find('_')]\n",
    "    if vulName not in labels:\n",
    "        labels.append(vulName)\n",
    "    for subFileItem in subFile:\n",
    "        codeFile = os.listdir(dirPath+\"/\"+file+\"/\"+subFileItem)\n",
    "        for codeFileItem in codeFile:\n",
    "            yaArr = np.zeros(len(labelsArr), dtype=int)\n",
    "            javaFilePath = dirPath+\"/\"+file+\"/\"+subFileItem+\"/\"+codeFileItem+\"/before/GenericClass.java\"\n",
    "            shutil.copy(javaFilePath, \"./\")\n",
    "            subprocess.call(['python3', './scripts/Importer.py', '-f','GenericClass.java', '-m',mode],    stdout=subprocess.DEVNULL,stderr=subprocess.STDOUT)\n",
    "            datasetArray.append(getDataSet(mode))\n",
    "            yaArr[labelsArr.index(file)]=1\n",
    "            labelsArray.append(yaArr.tolist())\n",
    "            os.remove(\"GenericClass.java\")\n",
    "            yaArr = np.zeros(len(labelsArr), dtype=int)\n",
    "            javaFilePath = dirPath+\"/\"+file+\"/\"+subFileItem+\"/\"+codeFileItem+\"/after/GenericClass.java\"\n",
    "            shutil.copy(javaFilePath, \"./\")\n",
    "            subprocess.call(['python3', './scripts/Importer.py', '-f','GenericClass.java', '-m',mode],    stdout=subprocess.DEVNULL,stderr=subprocess.STDOUT)\n",
    "            datasetArray.append(getDataSet(mode))\n",
    "            labelsArray.append(yaArr.tolist())\n",
    "            os.remove(\"GenericClass.java\")\n",
    "    print(file)\n",
    "graphs =datasetArray\n",
    "graph_labels = labelsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics of the sizes of the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
    "    columns=[\"nodes\", \"edges\"],\n",
    ")\n",
    "summary.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are array of binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labelsraw = pd.DataFrame(labelsArray)\n",
    "graph_labelsraw.value_counts().to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels = pd.get_dummies(graph_labelsraw, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare graph generator\n",
    "\n",
    "To feed data to the `tf.Keras` model that we will create later, we need a data generator. For supervised graph classification, we create an instance of `StellarGraph`'s `PaddedGraphGenerator` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = PaddedGraphGenerator(graphs=graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 35  # the number of rows for the output tensor\n",
    "layer_sizes = [32, 32, 32, 4]\n",
    "\n",
    "dgcnn_model = DeepGraphCNN(\n",
    "    layer_sizes=layer_sizes,\n",
    "    activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
    "    k=k,\n",
    "    bias=False,\n",
    "    generator=generator,\n",
    ")\n",
    "x_inp, x_out = dgcnn_model.in_out_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add the convolutional, max pooling, and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = Conv1D(filters=16, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
    "x_out = MaxPool1D(pool_size=2)(x_out)\n",
    "\n",
    "x_out = Conv1D(filters=32, kernel_size=5, strides=1)(x_out)\n",
    "\n",
    "x_out = Flatten()(x_out)\n",
    "\n",
    "\n",
    "x_out = Dense(units=128, activation=\"relu\")(x_out)\n",
    "\n",
    "x_out = Dense(units=64, activation=\"relu\")(x_out)\n",
    "\n",
    "x_out = Dropout(rate=0.5)(x_out)\n",
    "\n",
    "output1 = Dense(len(labelsArr), activation='sigmoid')(x_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the `Keras` model and prepare it for training by specifying the loss and optimisation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=x_inp, outputs=output1)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00001), loss=tf.keras.losses.binary_crossentropy,metrics=[tf.metrics.binary_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We can now train the model using the model's `fit` method.\n",
    "\n",
    "But first we need to split our data to training and test sets. We are going to use 90% of the data for training and the remaining 10% for testing. This 90/10 split is the equivalent of a single fold in the 10-fold cross validation scheme used in [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs, test_graphs = model_selection.train_test_split(\n",
    "    graph_labels, train_size=0.6,shuffle=True, stratify=graph_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data split into train and test sets, we create a `StellarGraph.PaddedGenerator` generator object that prepares the data for training. We create data generators suitable for training at `tf.keras` model by calling the latter generator's `flow` method specifying the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = PaddedGraphGenerator(graphs=graphs)\n",
    "\n",
    "train_gen = gen.flow(\n",
    "    list(train_graphs.index - 1),\n",
    "    targets=tf.convert_to_tensor(train_graphs.values),\n",
    "    symmetric_normalization=False,\n",
    ")\n",
    "test_gen = gen.flow(\n",
    "    list(test_graphs.index - 1),\n",
    "    targets=tf.convert_to_tensor(test_graphs.values),\n",
    "    symmetric_normalization=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We set the number of epochs to a large value so the call to `model.fit(...)` later might take a long time to complete. For faster performance set `epochs` to a smaller value; but if you do accuracy of the model found may be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model by calling it's `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen, epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the training history (losses and accuracies for the train and test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = sg.utils.plot_history(history,return_figure=True)\n",
    "pl.savefig(\"history-\"+mode+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us calculate the performance of the trained model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "with open('res'+mode+'binary.txt', 'w') as f:\n",
    "    for name, val in zip(model.metrics_names, test_metrics):\n",
    "        f.write(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "        f.write('\\n')\n",
    "\n",
    "        print(\"\\t{}: {:0.4f}\".format(name, val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('3.8.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "fca9ada9be7055bbb37cdeb1d76d1422c3da7716e11e132375b6710e22e1f379"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
